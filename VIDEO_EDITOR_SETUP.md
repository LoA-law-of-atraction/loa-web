# Video Editor Setup Guide

This guide explains how to integrate the LoA Video Editor with Make.com for automated video generation.

## Overview

The video editor workflow follows these steps:

1. **Generate Script & Images** (Make.com) → Posts to `/api/video-editor`
2. **User Approval** (Web Interface) → Approve/Regenerate individual scene images
3. **Generate Videos** (Make.com) → Receives approved images, generates videos
4. **Final Assembly** (Shotstack) → Combines videos + continuous voiceover

## Architecture

```
Make.com (Script Gen)
    ↓ POST /api/video-editor
Firestore (video_sessions collection)
    ↓
Admin Video Editor UI
    ↓ User Approves
Firestore (updated with approvals)
    ↓ PATCH /api/video-editor
Make.com (Video Generation)
    ↓
Shotstack (Final Assembly)
```

## Firestore Collection Structure

### Collection: `video_sessions`

```javascript
{
  session_id: "video_1738123456789_abc123",
  topic: "How I manifested my dream job",
  script: "Full continuous voiceover script (32 seconds)",
  selected_character: {
    character_id: "char_001",
    gender: "female",
    age_range: "30s",
    image_url: "https://...",
    voice_id: "elevenlabs_voice_id"
  },
  voiceover_url: "https://storage.googleapis.com/...",
  status: "pending_approval", // or "approved" or "generating_video" or "completed"
  scenes: [
    {
      id: 1,
      duration: "8s",
      location: "location_1",
      voiceover: "First 8 seconds of script...",
      camera: "medium",
      mood: "contemplative",
      image_prompt: "Dark cinematic cartoon style...",
      motion_prompt: "Slow breathing motion...",
      image_url: "https://...",  // Generated by Fal AI
      video_url: null,            // Generated after approval
      approved: false
    },
    // ... 3 more scenes
  ],
  created_at: "2026-01-29T12:00:00.000Z",
  updated_at: "2026-01-29T12:05:00.000Z"
}
```

## Make.com Scenario Updates

### Module After Claude (Module 29+)

After Claude generates the script (Module 28), add these modules:

#### 1. Parse JSON (Module 29)
Already exists. Make sure it parses the updated structure with `image_prompt` and `motion_prompt`.

#### 2. Generate Voiceover (ElevenLabs)
```json
{
  "text": "{{29.script}}",
  "model_id": "eleven_multilingual_v2",
  "output_format": "mp3_44100_128",
  "voice_settings": {
    "stability": 0.65,
    "similarity_boost": 0.75,
    "style": 0.1,
    "use_speaker_boost": true
  }
}
```

#### 3. Upload Voiceover to Cloud Storage
Upload the audio file and get a public URL.

#### 4. Generate 4 Images (Fal AI - text-to-image)
Create 4 parallel branches, one for each scene:

```json
{
  "prompt": "{{29.scenes[0].image_prompt}}",
  "image_size": "portrait_9_16",
  "num_images": 1
}
```

Repeat for scenes[1], scenes[2], scenes[3].

#### 5. Upload Images to Cloud Storage
Upload each generated image and get public URLs.

#### 6. POST to Video Editor API
```http
POST https://yourdomain.com/api/video-editor
Content-Type: application/json

{
  "topic": "{{1.topic}}",
  "script": "{{29.script}}",
  "selected_character": {
    "character_id": "{{99.character_id}}",
    "gender": "{{99.gender}}",
    "age_range": "{{99.age_range}}",
    "image_url": "{{99.image_url}}",
    "voice_id": "{{99.voice_id}}"
  },
  "voiceover_url": "{{voiceover_cloud_storage_url}}",
  "scenes": [
    {
      "id": 1,
      "duration": "8s",
      "location": "{{29.scenes[0].location}}",
      "voiceover": "{{29.scenes[0].voiceover}}",
      "camera": "{{29.scenes[0].camera}}",
      "mood": "{{29.scenes[0].mood}}",
      "image_prompt": "{{29.scenes[0].image_prompt}}",
      "motion_prompt": "{{29.scenes[0].motion_prompt}}",
      "image_url": "{{scene1_image_url}}"
    },
    // ... repeat for scenes 2-4
  ]
}
```

Response:
```json
{
  "success": true,
  "session_id": "video_1738123456789_abc123",
  "editor_url": "https://yourdomain.com/admin/video-editor?session=video_1738123456789_abc123"
}
```

#### 7. Send Email Notification
Send an email to admin with the editor URL for approval.

---

## New Make.com Scenarios Needed

### Scenario 2: Regenerate Single Scene Image

**Trigger:** Webhook (called from video editor when user clicks "Regenerate")

**Input:**
```json
{
  "session_id": "video_1738123456789_abc123",
  "scene_id": 2,
  "image_prompt": "Dark cinematic cartoon style...",
  "selected_character": {...}
}
```

**Steps:**
1. Generate new image (Fal AI text-to-image)
2. Upload to Cloud Storage
3. PATCH to update session:
   ```http
   PATCH https://yourdomain.com/api/video-editor
   Content-Type: application/json

   {
     "session_id": "video_1738123456789_abc123",
     "scene_id": 2,
     "image_url": "{{new_image_url}}"
   }
   ```

---

### Scenario 3: Generate Final Videos

**Trigger:** Webhook (called from video editor when user approves all scenes)

**Input:**
```json
{
  "session_id": "video_1738123456789_abc123",
  "approved_images": [
    {
      "scene_id": 1,
      "image_url": "https://...",
      "motion_prompt": "Slow breathing motion..."
    },
    // ... scenes 2-4
  ],
  "voiceover_url": "https://..."
}
```

**Steps:**

1. **Get Session Data from Firestore**
   ```javascript
   // Read from Firestore: video_sessions/{session_id}
   ```

2. **Generate 4 Videos (Fal AI image-to-video)**
   Create 4 parallel branches:
   ```json
   {
     "image_url": "{{approved_images[0].image_url}}",
     "prompt": "{{approved_images[0].motion_prompt}}",
     "duration": 8
   }
   ```
   Repeat for scenes 2-4.

3. **Upload Videos to Cloud Storage**
   Upload each generated video and get public URLs.

4. **Assemble in Shotstack**
   ```json
   {
     "timeline": {
       "tracks": [
         {
           "clips": [
             {
               "asset": {"src": "{{scene1_video_url}}", "type": "video", "volume": 0},
               "start": 0,
               "length": 8
             },
             {
               "asset": {"src": "{{scene2_video_url}}", "type": "video", "volume": 0},
               "start": 8,
               "length": 8
             },
             {
               "asset": {"src": "{{scene3_video_url}}", "type": "video", "volume": 0},
               "start": 16,
               "length": 8
             },
             {
               "asset": {"src": "{{scene4_video_url}}", "type": "video", "volume": 0},
               "start": 24,
               "length": 8
             }
           ]
         },
         {
           "clips": [
             {
               "asset": {"src": "{{voiceover_url}}", "type": "audio", "volume": 1},
               "start": 0,
               "length": "auto"
             }
           ]
         }
       ]
     },
     "output": {
       "format": "mp4",
       "resolution": "hd",
       "size": {
         "width": 1080,
         "height": 1920
       }
     }
   }
   ```

5. **Update Firestore with Final Video**
   ```javascript
   // Update video_sessions/{session_id}
   {
     status: "completed",
     final_video_url: "{{shotstack_output_url}}",
     scenes: [
       {
         ...existing_scene_data,
         video_url: "{{scene1_video_url}}"
       },
       // ... update all scenes
     ]
   }
   ```

6. **Update Google Sheets**
   Mark the row as completed with the final video URL.

---

## Environment Variables

Add these to your `.env` file:

```env
# Video Editor - Make.com Webhooks
NEXT_PUBLIC_MAKE_REGENERATE_WEBHOOK=https://hook.us1.make.com/your-regenerate-webhook-id
NEXT_PUBLIC_MAKE_GENERATE_VIDEO_WEBHOOK=https://hook.us1.make.com/your-generate-video-webhook-id
NEXT_PUBLIC_BASE_URL=https://yourdomain.com
```

---

## API Endpoints

### POST `/api/video-editor`
Create a new video editing session.

**Request:**
```json
{
  "topic": "string",
  "script": "string",
  "selected_character": {...},
  "voiceover_url": "string",
  "scenes": [...]
}
```

**Response:**
```json
{
  "success": true,
  "session_id": "string",
  "editor_url": "string"
}
```

---

### GET `/api/video-editor?session={session_id}`
Retrieve session data.

**Response:**
```json
{
  "success": true,
  "data": {...}
}
```

---

### PATCH `/api/video-editor`
Update scene approval status or image URL.

**Request:**
```json
{
  "session_id": "string",
  "scene_id": 1,
  "approved": true,
  "image_url": "string" // optional
}
```

**Response:**
```json
{
  "success": true,
  "data": {...}
}
```

---

## Testing

1. **Test Image Generation:**
   ```bash
   # Run Make scenario to generate script + images
   # Check Firestore for video_sessions document
   # Visit admin/video-editor?session={session_id}
   ```

2. **Test Approval Flow:**
   ```bash
   # Click "Approve" on each scene
   # Verify Firestore updates
   ```

3. **Test Regeneration:**
   ```bash
   # Click "Regenerate" on a scene
   # Check webhook is called
   # Verify new image appears
   ```

4. **Test Final Generation:**
   ```bash
   # Approve all scenes
   # Click "Generate Final Video"
   # Monitor Make scenario execution
   # Check Firestore for completed status
   ```

---

## Next Steps

1. ✅ Update Claude prompt to include `image_prompt` and `motion_prompt`
2. ✅ Create API endpoint at `/api/video-editor`
3. ✅ Create video editor admin page
4. ⏳ Update Make.com "LoA Shorts" scenario to POST to API endpoint
5. ⏳ Create Make.com "Regenerate Scene" scenario
6. ⏳ Create Make.com "Generate Videos" scenario
7. ⏳ Test end-to-end workflow
8. ⏳ Deploy to production

---

## Troubleshooting

### Issue: Session not found
- Check Firestore rules allow admin access
- Verify session_id is correct
- Check API endpoint logs

### Issue: Images not loading
- Verify Cloud Storage URLs are public
- Check CORS settings on storage bucket
- Verify image URLs are HTTPS

### Issue: Regenerate not working
- Check NEXT_PUBLIC_MAKE_REGENERATE_WEBHOOK is set
- Verify webhook URL in Make.com
- Check Make scenario is active

### Issue: Video generation failing
- Check all scenes are approved
- Verify Fal AI image-to-video API key
- Check motion prompts are valid
- Verify Shotstack API key and quota
